# Теория

## 1. Базовые сведения <a href="#ch1.1" id="ch1.1"></a>

### 1.1. Данные

Метод главных компонент применяется к данным, записанным в виде матрицы **X** – прямоугольной таблицы чисел размерностью _I_ строк и _J_ столбцов.

&#x20;![](https://www.chemometrics.ru/old/Tutorials/pca/fig01.gif)

Рис. 1 Матрица данных

Традиционно строки этой матрицы называются образцами. Они нумеруются индексом _i_, меняющимся от 1 до _I_. Столбцы называются переменными, и они нумеруются индексом _j_= 1, …, _J_.

Цель PCA – извлечение из этих данных нужной информации. Что является информацией, зависит от сути решаемой задачи. Данные могут содержать нужную нам информацию, они даже могут быть избыточными. Однако, в некоторых случаях, информации в данных может не быть совсем.&#x20;

Размерность данных –  число образцов и переменных – имеет большое значение для успешной добычи информации. Лишних данных не бывает – лучше, когда их много, чем мало. На практике это означает, что если получен спектр какого–то образца, то не нужно выбрасывать все точки, кроме нескольких характерных длин волн, а использовать их все, или, по крайней мере, значительный кусок.&#x20;

Данные всегда (или почти всегда) содержат в себе нежелательную составляющую, называемую шумом. Природа этого шума может быть различной, но, во многих случаях, шум – это та часть данных, которая не содержит искомой информации. Что считать шумом, а что – информацией, всегда решается с учетом поставленных целей и методов, используемых для ее достижения.&#x20;

Шум и избыточность в данных обязательно проявляют себя через корреляционные связи между переменными. Погрешности в данных могут привести к появлению не систематических, а случайных связей между переменными. Понятие эффективного (химического) ранга и скрытых, латентных переменных, число которых равно этому рангу, является важнейшим понятием в PCA

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 1.2. Интуитивный подход

Постараемся передать суть метода главных компонент, используя интуитивно–понятную геометрическую интерпретацию. Начнем с простейшего случая, когда имеются только две переменные _x_1 и _x_2. Такие данные легко изобразить на плоскости ([Рис. 2](https://www.chemometrics.ru/old/Tutorials/pca.htm#Fig02)).

![](https://www.chemometrics.ru/old/Tutorials/pca/fig02.gif)

Рис. 2 Графическое представление двумерных данных

Каждой строке исходной таблицы (т.е. образцу) соответствует точка на плоскости с соответствующими координатами. Они обозначены пустыми кружками на [Рис. 2](https://www.chemometrics.ru/old/Tutorials/pca.htm#Fig02). Проведем через них прямую, так, чтобы вдоль нее происходило максимальное изменение данных. На рисунке эта прямая выделена синим цветом; она называется первой главной компонентой –  PC1. Затем спроецируем все исходные точки на эту ось. Получившиеся точки закрашены красным цветом. Теперь мы можем предположить, что на самом деле все наши экспериментальные точки и должны были лежать на этой новой оси. Просто какие–то неведомые силы отклонили их от правильного, идеального положения, а мы вернули их на место. Тогда все отклонения от новой оси можно считать шумом, т.е. ненужной нам информацией. Правда, мы должны быть в этом уверены. Проверить шум ли это, или все еще важная часть данных, можно поступив с этими остатками так же, как мы поступили с исходными данными – найти в них ось максимальных изменений. Она называется второй главной компонентой (PC2). И так надо действовать, до тех пор, пока шум уже не станет действительно шумом, т.е. случайным хаотическим набором величин.

В общем, многомерном случае, процесс выделения главных компонент происходит так:&#x20;

1. Ищется центр облака данных, и туда переносится новое начало координат –  это нулевая главная компонента (PC0)&#x20;
2. Выбирается направление максимального изменения данных – это первая главная компонента (PC1)&#x20;
3. Если данные описаны не полностью (шум велик), то выбирается еще одно направление (PC2) – перпендикулярное к первому, так чтобы описать оставшееся изменение в данных и т.д.

&#x20; ![](https://www.chemometrics.ru/old/Tutorials/pca/data.gif)![](https://www.chemometrics.ru/old/Tutorials/pca/fig03.gif)

Рис. 3 Графическое представление метода главных компонент

В результате, мы переходим от большого количества переменных к новому представлению, размерность которого значительно меньше. Часто удается упростить данные на порядки: от 1000 переменных перейти всего к двум. При этом ничего не выбрасывается – все переменные учитываются. В то же время несущественная для сути дела часть данных отделяется, превращается в шум. Найденные главные компоненты и дают нам искомые скрытые переменные, управляющие устройством данных.

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 1.3. Понижение размерности

Суть метода главных компонент – это существенное понижение размерности данных. Исходная матрица **X** заменяется двумя новыми матрицами **T** и **P**, размерность которых, _A_, меньше, чем число переменных (столбцов) _J_ у исходной матрицы **X**

![](https://www.chemometrics.ru/old/Tutorials/pca/fig04.png)

Рис. 4 Декомпозиция матрицы **X**

Вторая размерность – число образцов (строк) _I_ сохраняется. Если декомпозиция выполнена правильно – размерность _A_ выбрана верно, то матрица **T** несет в себе столько же информации, сколько ее было в начале, в матрице **X**. При этом матрица **T** меньше, и, стало быть, проще, чем **X**.

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

## 2. Метод главных компонент <a href="#ch2.1" id="ch2.1"></a>

### 2.1. Формальное описание

Пусть имеется матрица переменных **X** размерностью (_I_×_J_), где _I_ – число образцов (строк), а _J_ – это число независимых переменных (столбцов), которых, как правило, много (_J_>>1). В методе главных компонент используются новые, формальные переменные **t**a (_a_=1,…_A_), являющиеся линейной комбинацией исходных переменных **x**_j_ (_j_=1,…_J_) \


|    **t**_a_=**p**_a_1**x**1+… + **p**_aJ_**x**_J_ | (1) |
| ------------------------------------------------- | --- |

С помощью этих новых переменных матрица **X** разлагается в произведение двух матриц **T** и **P** –\


| <img src="https://www.chemometrics.ru/old/Tutorials/pca/image01.gif" alt="" data-size="original"> | (2) |
| ------------------------------------------------------------------------------------------------- | --- |

Матрица **T** называется матрицей _счетов_ (scores). Ее размерность (_I_×_A_).&#x20;

Матрица **P** называется матрицей _нагрузок_ (loadings). Ее размерность (_J_×_A_).&#x20;

**E** – это матрица _остатков_, размерностью (_I_×_J_).

![](https://www.chemometrics.ru/old/Tutorials/pca/fig05.gif)

&#x20;

Рис. 5 Разложение по главным компонентам

Новые переменные **t**_a_ называются _главными компонентами_ (Principal Components), поэтому и сам метод называется методом главных компонент (PCA). Число столбцов – **t**_a_ в матрице **T**, и **p**_a_ в матрице **P**, равно _A_, которое называется _числом главных компонент_ (PC). Эта величина заведомо меньше числа переменных _J_ и числа образцов _I_.&#x20;

Важным свойством PCA является _ортогональность_ (независимость) главных компонент. Поэтому матрица счетов **T** не перестраивается при увеличении числа компонент, а к ней просто прибавляется еще один столбец – соответствующий новому направлению. Тоже происходит и с матрицей нагрузок **P**.

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 2.2. Алгоритм&#x20;

Чаще всего для построения PCA счетов и нагрузок, используется рекуррентный алгоритм [NIPALS](https://www.chemometrics.ru/old/Tutorials/projection.htm#Ch1.2), который на каждом шагу вычисляет одну компоненту. Сначала исходная матрица **X** преобразуется (как минимум – центрируется; см. раздел [2.12](https://www.chemometrics.ru/old/Tutorials/pca.htm#Ch2.12))  и превращается в матрицу **E**0, _a_=0. Далее применяют следующий алгоритм.&#x20;

> 1\. Выбрать начальный вектор **t** 2. **p**t = **t**t **E**_a_ / **t**t**t** 3. **p** = **p** / (**p**t**p**)½4. **t** = **E**_a_ **p** / **p**t**p**5. Проверить сходимость, если нет, то идти на 2

После вычисления очередной (_a-_ой) компоненты, полагаем **t**_a_=**t** и **p**_a_=**p**. Для получения следующей компоненты надо вычислить остатки **E**_a_+1 = **E**_a_ – **t** **p**t и применить к ним тот же алгоритм, заменив индекс _a_ на _a_+1. Программа для реализации PCA в среде MatLab приведена в пособии [MatLab. Руководство для начинающих](https://www.chemometrics.ru/old/Tutorials/matlab.htm#Ch5.3) .&#x20;

В этом пособии для построения PCA используется специальная надстройка для программы Excel (Add–In) _Chemometrics.xla_. Она дополняет список стандартных функций Excel и позволяет проводить PCA разложение на листах рабочей книги. Подробности об этой программе можно прочитать в пособии [Проекционные методы в системе Excel.](https://www.chemometrics.ru/old/Tutorials/projection.htm)

После того, как построено пространство из главных компонент, новые образцы **X**new могут быть на него спроецированы, иными словами – определены матрицы их счетов **T**new. В методе PCA это делается очень просто&#x20;

| **T**new.=. **X**new **P** | (3) |
| -------------------------- | --- |

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 2.3. PCA и SVD

Метод главных компонент тесно связан с другим разложением – [по сингулярным значениям, SVD](https://www.chemometrics.ru/old/Tutorials/matrix.htm#ch211). В последнем случае исходная матрица **X** разлагается в произведение трех матриц&#x20;

**X**=**USV**t&#x20;

Здесь **U** – матрица, образованная ортонормированными собственными векторами **u**_r_ матрицы **XX**t, соответствующим значениям λ_r_;&#x20;

**XX**t**u**_r_ = λ_r_**u**_r_;&#x20;

**V**– матрица, образованная ортонормированными собственными векторами **v**_r_ матрицы **X**t**X**;&#x20;

**X**t**Xv**_r_ = λ_r_**v**_r_;&#x20;

**S** – положительно определенная диагональная матрица, элементами которой являются [сингулярные значения](https://www.chemometrics.ru/old/Tutorials/matrix.htm#ch211) σ1≥... ≥σR≥0 равные квадратным корням из собственных значений λ_r_

![](https://www.chemometrics.ru/old/Tutorials/pca/image03.gif)

Связь между PCA и SVD определяется следующими простыми соотношениями&#x20;

**T** = **US** **P** = **V**

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 2.4. Счета

Матрица счетов **T** дает нам проекции исходных образцов (_J_ –мерных векторов **x**1,…,**x**_I_) на подпространство главных компонент (_A-_мерное). Строки **t**1,…,**t**_I_ матрицы **T** – это координаты образцов в новой системе координат. Столбцы **t**1,…,**t**_A_ матрицы **T** – ортогональны и представляют проекции всех образцов на одну новую координатную ось.&#x20;

При исследовании данных методом PCA, особое внимание уделяется графикам счетов. Они несут в себе информацию, полезную для понимания того, как устроены данные. На графике счетов каждый образец изображается в координатах (**t**_i_, **t**_j_), чаще всего – (**t**1, **t**2), обозначаемых PC1 и PC2. Близость двух точек означает их схожесть, т.е. положительную [корреляцию](https://www.chemometrics.ru/old/Tutorials/statistics.htm#Ch1.9). Точки, расположенные под прямым углом, являются некоррелироваными, а расположенные диаметрально противоположно – имеют отрицательную корреляцию.

![](https://www.chemometrics.ru/old/Tutorials/pca/fig06a.gif)              ![](https://www.chemometrics.ru/old/Tutorials/pca/fig06b.gif)

Рис.6 График счетов

Подробнее о том, как из графиков счетов извлекается полезная информация, будет рассказано в примере.&#x20;

Для матрицы счетов имеют место следующие соотношения –

**T**t**T** = **Λ**= diag{ λ1,…,λ_A_},&#x20;

где величины λ1≥... ≥λ_A_≥0  – это [собственные значения](https://www.chemometrics.ru/old/Tutorials/matrix.htm#ch207). Они характеризуют важность каждой компоненты\


| ![](https://www.chemometrics.ru/old/Tutorials/pca/image04.gif) | (4) |
| -------------------------------------------------------------- | --- |

Нулевое собственное значение λ0 определяется как сумма всех собственных значений, т.е.

&#x20;

| ![](https://www.chemometrics.ru/old/Tutorials/pca/image05.gif) | (5) |
| -------------------------------------------------------------- | --- |

Для вычисления PCA-счетов в надстройке _Chemometrics Add-In_ используется функция [**ScoresPCA**](https://www.chemometrics.ru/old/Tutorials/projection.htm#Ch3.1).

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 2.5. Нагрузки&#x20;

Матрица нагрузок **P** – это матрица перехода из исходного пространства переменных **x**1, …**x**_J_ (_J-_мерного) в пространство главных компонент (_A-_мерное). Каждая строка матрицы **P** состоит из коэффициентов, связывающих переменные **t** и **x** ([1](https://www.chemometrics.ru/old/Tutorials/pca.htm#Eq1)). Например, _a-_я строка – это проекция всех переменных **x**1, …**x**_J_ на _a-_ю ось главных компонент. Каждый столбец **P** – это проекция соответствующей переменной **x**_j_ на новую систему координат.

![](https://www.chemometrics.ru/old/Tutorials/pca/fig07a.gif)          ![](https://www.chemometrics.ru/old/Tutorials/pca/fig07b.gif)

Рис.7 График нагрузок

График нагрузок применяется для исследования роли переменных. На этом графике каждая переменная **x**_j_ отображается точкой в координатах (**p**_i_, **p**_j_), например (**p**1, **p**2). Анализируя его аналогично графику счетов, можно понять, какие переменные связаны, а какие независимы. Совместное исследование парных графиков счетов и нагрузок, также может дать много полезной информации о данных.&#x20;

В методе главных компонент нагрузки – это ортогональные нормированные вектора, т.е.&#x20;

**P**t**P** = **I**

Для вычисления PCA-нагрузок в надстройке _Chemometrics Add-In_ используется функция [**LoadingsPCA**](https://www.chemometrics.ru/old/Tutorials/projection.htm#Ch3.2).

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 2.6. Данные специального вида

Результат моделирования методом главных компонент не зависит от порядка, в котором следуют образцы и/или переменные. Иными словами строки и столбцы в исходной матрице **X** можно переставить, но ничего принципиально не изменится. Однако, в некоторых случаях, сохранять и отслеживать этот порядок очень полезно – это позволяет лучше понять устройство моделируемых данных.

![](https://www.chemometrics.ru/old/Tutorials/pca/fig08.png)

Рис. 8 Данные ВЭЖХ–ДДМ

Рассмотрим простой пример – моделирование данных, полученных методом высокоэффективной жидкостной хроматографией с детектированием на диодной матрице (ВЭЖХ–ДДМ). Данные представляются матрицей, размерностью 30 образцов (_I_) на 28 переменных (_J_). Образцы соответствуют временам удерживания от 0 до 30 с, а переменные – длинам волн от 220 до 350 нм, на которых происходит детектирование. Данные ВЭЖХ–ДДМ представлены на [Рис 8](https://www.chemometrics.ru/old/Tutorials/pca.htm#Fig08).&#x20;

Эти данные хорошо моделируются методом PCA с двумя главными компонентами. Ясно, что в этом примере нам важен порядок, в котором идут образцы и переменные – он задается естественным ходом времени и спектральным диапазоном. Полученные счета и нагрузки полезно изобразить на графиках в зависимости от соответствующего параметра – счета от времени, а нагрузки от длины волны. (см. [Рис 9](https://www.chemometrics.ru/old/Tutorials/pca.htm#Fig10))

![](https://www.chemometrics.ru/old/Tutorials/pca/fig09a.gif)    ![](https://www.chemometrics.ru/old/Tutorials/pca/fig09b.gif)

Рис. 9 Графики счетов и нагрузок для данных ВЭЖХ–ДДМ

Подробнее этот пример разобран в пособии [Разрешение многомерных кривых](https://www.chemometrics.ru/old/Tutorials/mcr.htm#Ch2.2) .

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 2.7. Погрешности&#x20;

PCA декомпозиция матрицы **X** является последовательным, итеративным процессом, который можно оборвать на любом шаге _a_=_A_. Получившаяся матрица

![](https://www.chemometrics.ru/old/Tutorials/pca/image06.gif)

вообще говоря, отличается от матрицы X. Разница между ними&#x20;

![](https://www.chemometrics.ru/old/Tutorials/pca/image07.gif)

называется _матрицей остатков_.

Рассмотрим геометрическую интерпретацию остатков. Каждый исходный образец **x**_i_ (строка в матрице **X**) можно представить как вектор в _J_– мерном пространстве с координатами

![](https://www.chemometrics.ru/old/Tutorials/pca/image08.gif)

![](https://www.chemometrics.ru/old/Tutorials/pca/fig10.gif)

Рис. 10 Геометрия PCA

PCA проецирует его в вектор, лежащий в пространстве главных компонент, **t**_i_=(**t**_i_1, **t**_i_2, …**t**_iA_) размерностью _A_. В исходном пространстве этот же вектор **t**i имеет координаты

![](https://www.chemometrics.ru/old/Tutorials/pca/image09.gif)

Разница между исходным вектором и его проекцией является вектором остатков&#x20;

![](https://www.chemometrics.ru/old/Tutorials/pca/image10.gif)

Он образует _i_–ю строку в матрице остатков **E**.

![](https://www.chemometrics.ru/old/Tutorials/pca/fig11.gif)

Рис.11 Вычисление остатков&#x20;

Исследуя остатки можно понять, как устроены данные и хорошо ли они описываются PCA моделью.&#x20;

Для вычисления PCA-остатков можно использовать приемы, описанные в пособии [Расширение возможностей Chemometrics Add-In](https://www.chemometrics.ru/old/Tutorials/tricks.htm).

Величина  –&#x20;

| <img src="https://www.chemometrics.ru/old/Tutorials/pca/image11.gif" alt="" data-size="original"> | (6) |
| ------------------------------------------------------------------------------------------------- | --- |

определяет квадрат отклонения исходного вектора **x**_i_ от его проекции на пространство PC. Чем оно меньше, тем лучше приближается _i_–ый образец.&#x20;

Для вычисления отклонений можно использовать [стандартные функции листа](https://www.chemometrics.ru/old/Tutorials/tricks.htm#Ch1.7) или [специальную пользовательскую функцию](https://www.chemometrics.ru/old/Tutorials/tricks.htm#Ch2.6).

Эта же величина, деленная на число переменных&#x20;

![](https://www.chemometrics.ru/old/Tutorials/pca/image12.gif)

дает [оценку дисперсии](https://www.chemometrics.ru/old/Tutorials/statistics.htm#Ch3.5) (вариации) _i_–го образца.&#x20;

Среднее (для всех образцов) расстояние _v_0 вычисляется как&#x20;

![](https://www.chemometrics.ru/old/Tutorials/pca/image13.gif)

Оценка общая (для всех образцов) дисперсии вычисляется так –

![](https://www.chemometrics.ru/old/Tutorials/pca/image14.gif)

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 2.8. Проверка&#x20;

В случае, когда PCA модель предназначена для предсказания или для классификации, а не для простого исследования данных, такая модель нуждается в подтверждении (валидации). При проверке методом тест–валидации исходный массив данных состоит из двух независимо полученных наборов, каждый из которых является достаточно представительным. Первый набор, называемый обучающим, используется для моделирования. Второй набор, называемый проверочным, служит только для проверки модели. Построенная модель применяется к данным из проверочного набора, и полученные результаты сравниваются с проверочными значениями. Таким образом принимается решение о правильности, точности моделирования.

![](https://www.chemometrics.ru/old/Tutorials/pca/fig12.gif)

Рис.12 Обучающий и проверочный наборы

В некоторых случаях объем данных слишком мал для такой проверки. Тогда применяют другой метод – перекрестной проверки (кросс–валидация), о котором можно прочитать [здесь](https://www.chemometrics.ru/old/Tutorials/calibration.htm#Ch1.3).

Используется также проверка методом коррекции размахом, суть которой предлагается изучить самостоятельно.

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 2.9. "Качество" декомпозиции&#x20;

Результатом PCA моделирования являются величины ![](https://www.chemometrics.ru/old/Tutorials/pca/image15.gif)– оценки, найденные по модели, построенной на обучающем наборе **X**c. Результатом проверки служат величины ![](https://www.chemometrics.ru/old/Tutorials/pca/image16.gif)– оценки проверочных значений **X**t, вычисленные по той же модели, но как новые образцы ([3](https://www.chemometrics.ru/old/Tutorials/pca.htm#Eq3)). Отклонение оценки от проверочного значения вычисляют как матрицу остатков: в обучении&#x20;

![](https://www.chemometrics.ru/old/Tutorials/pca/image17.gif),

и в проверке

![](https://www.chemometrics.ru/old/Tutorials/pca/image18.gif).

Следующие величины характеризуют "качество" моделирования в среднем.&#x20;

Полная [дисперсия](https://www.chemometrics.ru/old/Tutorials/statistics.htm#Ch3.6) остатков в обучении (TRVC) и в проверке (TRVP) –\
&#x20;

| ![](https://www.chemometrics.ru/old/Tutorials/pca/image19.gif)                    ****                    ![](https://www.chemometrics.ru/old/Tutorials/pca/image20.gif) |   |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | - |

Полная дисперсия выражается в тех же единицах (точнее их квадратах), что и исходные величины X.&#x20;

Объясненная дисперсия остатков в обучении (ERVC) и в проверке (ERVP) \
&#x20;

| ![](https://www.chemometrics.ru/old/Tutorials/pca/image21.gif)                       ****                       ![](https://www.chemometrics.ru/old/Tutorials/pca/image22.gif) |   |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | - |

Объясненная дисперсия – это относительная величина. При ее вычислении используется естественная нормировка – сумма квадратов всех исходных величин _xij_. Обычно она выражается в процентах или в долях единицы. Во всех этих формулах величины _eij_ – это элементы матриц **E**c или **E**t. Для характеристик, наименование которых оканчивается на C (например, TRVC), используется матрица **E**c (обучение), а для тех, которые оканчиваются на P (например, TRVP), берется матрица **E**t (проверка).

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 2.10. Выбор числа главных компонент&#x20;

Как уже отмечалось выше, метод главных компонент – это итерационная процедура, в которой новые компоненты добавляются последовательно, одна за другой. Важно знать, когда остановить этот процесс, т.е. как определить правильное число главных компонент, A. Если это число слишком мало, то описание данных будет не полным. С другой стороны, избыточное число главных компонент приводит к переоценке, т.е. к ситуации, когда моделируется шум, а не содержательная информация.

Для выбора значения числа главных компонент обычно используется график, на котором объясненная дисперсия (ERV) изображается в зависимости от числа PC. Пример такого графика приведен на [Рис. 13](https://www.chemometrics.ru/old/Tutorials/pca.htm#Fig13).

![](https://www.chemometrics.ru/old/Tutorials/pca/fig13.gif)

Рис. 13 Выбор числа PC

Из этого графика видно, что правильное число PC – это 3 или 4. Три компоненты объясняют 95%, а четыре 98% исходной вариации. Окончательное решение о величине _A_ можно принять только после содержательного анализа данных.&#x20;

Другим полезным инструментом является график, на котором изображаются собственные значения ([4](https://www.chemometrics.ru/old/Tutorials/pca.htm#Eq4)) в зависимости от числа PC. Пример показан на [Рис.14](https://www.chemometrics.ru/old/Tutorials/pca.htm#Fig14).

![](https://www.chemometrics.ru/old/Tutorials/pca/fig14.gif)

Рис. 14 График собственных значений

Из этого рисунка опять видно, что для _a_=3 происходит резкое изменение формы графика – излом. Поэтому верное число PC – это три или четыре.&#x20;

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 2.11. Неединственность PCA&#x20;

Разложение по методу главных компонент

![](https://www.chemometrics.ru/old/Tutorials/pca/image23.gif)

не является единственным. Вместо матриц **T** и **P** можно использовать другие матрицы  ![](https://www.chemometrics.ru/old/Tutorials/pca/image24.gif)и  ![](https://www.chemometrics.ru/old/Tutorials/pca/image25.gif), которые дадут аналогичную декомпозицию

![](https://www.chemometrics.ru/old/Tutorials/pca/image26.gif)

с той же матрицей ошибок **E**. Простейший пример – это одновременное изменение знаков у соответствующих компонент векторов **t**_a_ и **p**_a_, при котором произведение&#x20;

![](https://www.chemometrics.ru/old/Tutorials/pca/image27.gif)

остается неизменным. Алгоритм [NIPALS](https://www.chemometrics.ru/old/Tutorials/pca.htm#Ch2.2) дает именно такой результат – с точностью до знака, поэтому его реализация в разных программах может приводить к расхождениям в направлениях главных компонент.

Более сложный случай – это одновременное вращение матриц **T** и **P**. Пусть **R** – это ортогональная матрица вращения размерностью _A_×_A_ , т.е такая матрица, что **R**t=**R**–1. Тогда

![](https://www.chemometrics.ru/old/Tutorials/pca/image28.gif)

Заметим, что новые матрицы счетов и нагрузок сохраняют все свойства старых,

![](https://www.chemometrics.ru/old/Tutorials/pca/image29.gif).

Это свойство PCA называется вращательной неопределенностью. Оно интенсивно используется при решении задач разделения кривых, в частности методом [прокрустова вращения](https://www.chemometrics.ru/old/Tutorials/mcr.htm#Ch3.1). Если отказаться от условий ортогональности главных компонент, то декомпозиция матрицы станет еще более общей. Пусть теперь **R** – это произвольная невырожденная матрица размерностью _A_×_A_ . Тогда

![](https://www.chemometrics.ru/old/Tutorials/pca/image30.gif)

Эти матрицы счетов и нагрузок уже не удовлетворяют условию ортогональности и нормирования. Зато они могут состоять только из неотрицательных элементов, а также подчиняться другим требованиям, накладываемым при решении задач разделения сигналов.

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 2.12. Подготовка данных&#x20;

Во многих случаях, перед применением PCA, исходные данные нужно предварительно подготовить: отцентрировать и/или отнормировать. Эти преобразования проводятся по столбцам – переменным.&#x20;

_Центрирование_ – это вычитание из каждого столбца **x**_j_ среднего (по столбцу) значения&#x20;

![](https://www.chemometrics.ru/old/Tutorials/pca/image31.gif).

Центрирование необходимо потому, что оригинальная PCA модель ([2](https://www.chemometrics.ru/old/Tutorials/pca.htm#Eq2)) не содержит свободного члена.&#x20;

Второе простейшее преобразование данных – это _нормирование_. Это преобразование выравнивает вклад разных переменных в PCA модель. При этом преобразовании каждый столбец **x**_j_ делится на свое стандартное отклонение.

![](https://www.chemometrics.ru/old/Tutorials/pca/image32.gif)

Комбинация центрирования и нормирования по столбцам называется _автошкалированием_.&#x20;

![](https://www.chemometrics.ru/old/Tutorials/pca/image33.gif)

Любое преобразование данных – центрирование, нормирование, и т.п. – всегда делается сначала на обучающем наборе. По этому набору вычисляются значения _mj_ и _sj_, которые затем применяются и к обучающему, и к проверочному набору.&#x20;

В надстройке _Chemometrics Add In_ подготовка данных проводится [автоматически](https://www.chemometrics.ru/old/Tutorials/projection.htm#nCent). Если подготовку нужно провести вручную, то для нее можно использовать [стандартные функции листа](https://www.chemometrics.ru/old/Tutorials/tricks.htm#Ch1.3) или [специальную пользовательскую функцию](https://www.chemometrics.ru/old/Tutorials/tricks.htm#Ch2.3).

В задачах, где структура исходных данных **X** априори предполагает однородность и гомоскедастичность, подготовка данных не только не нужна, но и вредна. Именно такой случай представляют ВЭЖХ–ДДМ данные, рассмотренные в пособии [Разрешение многомерных кривых.](https://www.chemometrics.ru/old/Tutorials/mcr.htm#Ch2.3)

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 2.13. Размах и отклонение&#x20;

При заданном числе главных компонент _A_, величина

![](https://www.chemometrics.ru/old/Tutorials/pca/image35.gif)

называется _размахом_ (leverage). Эта величина равна квадрату расстояния Махаланобиса от центра модели до _i_–го образца в пространстве счетов, поэтому размах характеризует как далеко находится каждый образец в гиперплоскости главных компонент.

Для размаха имеет место соотношение

![](https://www.chemometrics.ru/old/Tutorials/pca/image36.gif)

которое выполняется тождественно – по построению PCA.

Для вычисления размахов можно использовать [стандартные функции листа](https://www.chemometrics.ru/old/Tutorials/tricks.htm#Ch1.8) или [специальную пользовательскую функцию](https://www.chemometrics.ru/old/Tutorials/tricks.htm#Ch2.7).

Другой важной характеристикой PCA модели является _отклонение_ _vi_, которое вычисляется как сумма квадратов остатков ([6](https://www.chemometrics.ru/old/Tutorials/pca.htm#Eq6)) – квадрат эвклидова расстояния от плоскости главных компонент до объекта _i_.

Для вычисления отклонений можно использовать [стандартные функции листа](https://www.chemometrics.ru/old/Tutorials/tricks.htm#Ch1.7) или [специальную пользовательскую функцию](https://www.chemometrics.ru/old/Tutorials/tricks.htm#Ch2.6).

Две эти величины: _hi_ и _vi_ определяют положение объекта (образца) относительно имеющейся PCA модели. Слишком большие значения размаха и/или отклонения свидетельствуют об особенности такого объекта, который может быть экстремальным или выпадающим образцом.

Анализ величин  _hi_ и _vi_ составляет основу [SIMCA](https://www.chemometrics.ru/old/Tutorials/classification.htm#Ch3.4) – метода классификации с обучением.

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

&#x20;

## 3. Люди и страны <a href="#ch3.1" id="ch3.1"></a>

### 3.1. Пример&#x20;

Метод главных компонент иллюстрируется примером, помещенным в файл [People.xls](https://www.chemometrics.ru/old/Tutorials/pca/People.xls).&#x20;

Этот файл включает в себя следующие листы:&#x20;

> [_Intro_](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Intro!C4): краткое введение&#x20;
>
> [_Layout_](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Layout!A1): схемы, объясняющая имена массивов, используемых в примере
>
> [_Data_](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Data!A1): данные, используемые в примере.&#x20;
>
> [_MVA_](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#MVA!A1): PCA декомпозиция, выполненная с помощью надстройки [_Chemometrics.xla_ ](https://www.chemometrics.ru/old/Tutorials/projection.htm)
>
> [_PCA_](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#PCA!A1): копия всех результатов PCA не привязанная к надстройке _Chemometrics.xla_&#x20;
>
> [_Scores1–2_](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#'Scores1-2'!A1): анализ младших счетов PC1–PC2
>
> [_Scores3–4_](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#'Scores3-4'!A1): анализ старших счетов PC3–PC4
>
> [_Loadings_](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Loadings!A1): анализ нагрузок
>
> [_Residuals_](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Residuals!A1): анализ остатков

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 3.2. Данные&#x20;

Анализ базируется на данных европейского демографического исследования, опубликованных в книге [К. Эсбенсена](https://www.chemometrics.ru/old/Tutorials/references.htm#L3.1).&#x20;

По причинам дидактического характера используется лишь небольшой набор из 32 человек, из которых 16 представляют Северную Европу (Скандинавия) и столько же – Южную (Средиземноморье). Для баланса выбрано одинаковое количество мужчин и женщин – по 16 человек. Люди характеризуются двенадцатью переменными, перечисленными в [Табл. 1](https://www.chemometrics.ru/old/Tutorials/pca.htm#Tab1).

Табл. 1 Переменные, использованные в демографическом анализе\
&#x20;

| _Height_    | Рост: в сантиметрах                                          |
| ----------- | ------------------------------------------------------------ |
| _Weight_    | Вес: в килограммах                                           |
| _Hair_      | Волосы: короткие: –1, или длинные: +1                        |
| _Shoes_     | Обувь: размер по европейскому стандарту                      |
| _Age_       | Возраст: в годах                                             |
| _Income_    | Доход: в тысячах евро в год                                  |
| _Beer_      | Пиво: потребление в литрах в год                             |
| _Wine_      | Вино: потребление в литрах в год                             |
| _Sex_       | Пол: мужской: –1, или женский: +1                            |
| _Strength_  | Сила: индекс, основанный на проверке физических способностей |
| _Region_    | Регион: север : –1, или юг: +1                               |
| _IQ_        | Коэффициент интеллекта, измеряемый по стандартному тесту     |

Заметим, что такие переменные, как _Sex_, _Hair_ и _Region_ имеют дискретный характер с двумя возможными значениями: –1 или +1, тогда как остальные девять переменных могут принимать непрерывные числовые значения.

[![](https://www.chemometrics.ru/old/Tutorials/pca/fig15.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Data!A1)

Рис. 15 Исходные данные в примере People

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 3.3. Исследование данных&#x20;

Прежде всего, любопытно посмотреть на графиках, как связаны между собой все эти переменные. Зависит ли рост (_Height_ ) от веса (_Weight_)? Отличаются ли женщины от мужчин в потреблении вина (_Wine_)? Связан ли доход (_Income_) с возрастом (_Age_)? Зависит ли вес (_Weight_) от потребления пива (_Beer_)?&#x20;

[![](https://www.chemometrics.ru/old/Tutorials/pca/fig16a.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Data!P2)  [![](https://www.chemometrics.ru/old/Tutorials/pca/fig16b.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Data!V2)\
[![](https://www.chemometrics.ru/old/Tutorials/pca/fig16c.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Data!P26)  [![](https://www.chemometrics.ru/old/Tutorials/pca/fig16d.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Data!V26)

Рис. 16 Связи между переменными в примере People. \
Женщины (F) обозначены кружками ● и ●, а мужчины (M) – квадратами ■ и ■. \
Север (N) представлен голубым ■, а юг (S) – красным цветом ●.

Некоторые из этих зависимостей показаны на [Рис.16](https://www.chemometrics.ru/old/Tutorials/pca.htm#Fig16). Для наглядности на всех графиках использованы одни и те же обозначения: женщины (F) показаны кружками, мужчины (M) – квадратами, север (N) представлен голубым, а юг (S) – красным цветом.

Связь между весом (_Weight_) и ростом (_Height_) показана на Рис.16a. Очевидна, прямая (положительная) пропорциональность. Учитывая маркировку точек, можно заметить также, что мужчины (M) в большинстве своем тяжелее и выше женщин (F). &#x20;

На Рис. 16b показана другая пара переменных: вес (_Weight_) и пиво (_Beer_). Здесь, помимо очевидных фактов, что большие люди пьют больше, а женщины – меньше, чем мужчины, можно заметить еще две отдельные группы – южан и северян. Первые пьют меньше пива при том же весе.

Эти же группы заметны и на Рис.16c, где показана зависимость между потреблением вина (_Wine_)  и пива (_Beer_). Из него видно, что связь между этими переменными отрицательна – чем больше потребляется пива, тем меньше вина. На юге пьют больше вина, а на севере – пива. Интересно, что в обеих группах женщины располагаются слева, но не ниже по отношению к мужчинам. Это означает, что, потребляя меньше пива, прекрасный пол не уступает в вине.

Последний график на Рис. 16d показывает, как связаны возраст (_Age_) и доход (_Income_). Легко видеть, что даже в этом сравнительно небольшом наборе данных есть переменные, как с положительной, так и с отрицательной корреляцией.&#x20;

Можно ли построить графики для всех пар переменных выборки? Вряд ли. Проблема состоит в том, что для 12 переменных существует 12(12–1)/2=66 таких комбинаций.&#x20;

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 3.4. Подготовка данных&#x20;

Перед тем, как подвергнуть данные анализу методом главных компонент, их надо подготовить. Простой статистический расчет показывает, что они нуждаются в [автошкалировании](https://www.chemometrics.ru/old/Tutorials/pca.htm#Ch2.12) (См. Рис. 17)

[![](https://www.chemometrics.ru/old/Tutorials/pca/fig17.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Data!O53)

Рис. 17 Средние значения и СКО для переменных в примере People.&#x20;

Средние значения по многим переменным отличаются от нуля. Кроме того, среднеквадратичные отклонения сильно разнятся. После автошкалирования среднее значение всех переменных становится равно нулю, а отклонение – единица.

[![](https://www.chemometrics.ru/old/Tutorials/pca/fig18.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Data!A39)

Рис. 18 Автошкалированные данные в примере People.&#x20;

В принципе, данные можно было бы не преобразовывать явно, на листе, а оставить как есть. Ведь стандартные хемометрические процедуры, собранные в программе _Chemometrics_ могут [центрировать и шкалировать ](https://www.chemometrics.ru/old/Tutorials/projection.htm#nCent)данные при выполнении вычислений. Однако матрица автошкалированных данных понадобится нам при вычислении остатков в [разделе 3.8 ](https://www.chemometrics.ru/old/Tutorials/pca.htm#Ch3.8).

&#x20;[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 3.5. Вычисление счетов и нагрузок&#x20;

Для построения PCA декомпозиции можно воспользоваться стандартными функциями [**ScoresPCA**](https://www.chemometrics.ru/old/Tutorials/projection.htm#Ch3.1) и [**LoadingsPCA**](https://www.chemometrics.ru/old/Tutorials/projection.htm#Ch3.2), имеющимися в надстройке _Chemometrics_. Мы вычислим все 12 возможных главных компонент. В качестве первого аргумента используется исходный, не преобразованный массив данных, поэтому последний аргумент в обеих функциях равен 3 – автошкалирование.

[![](https://www.chemometrics.ru/old/Tutorials/pca/fig19.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#MVA!B4)

Рис. 19 Вычисление матрицы счетов&#x20;

[![](https://www.chemometrics.ru/old/Tutorials/pca/fig20.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#MVA!P4)

Рис. 20 Вычисление матрицы нагрузок

В этом пособии все PCA вычисления проводятся в книге _People.xls_ на листе [_MVA_](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#MVA!A1). Для удобства читателя эти же результаты продублированы на листе [_PCA_](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#PCA!A1) как числа, без ссылки на надстройку _Chemometrics.xla_. Остальные листы рабочей книги связаны не с данными на листе _MVA_, с данными на листе PCA. Поэтому файл _People.xls_ можно использовать даже тогда, когда надстройка _Chemometrics.xla_ не установлена на  компьютере.

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 3.6. Графики счетов&#x20;

Посмотрим на графики счетов, которые показывают, как расположены образцы в проекционном пространстве.&#x20;

На графике младших счетов PC1–PC2 ([Рис. 21](https://www.chemometrics.ru/old/Tutorials/pca.htm#Fig21)) мы видим четыре отдельные группы, разложенные по четырем квадрантам: слева – женщины (F), справа – мужчины (M), сверху – юг (S), а снизу – север (N). Из этого сразу становится ясен смысл первых двух направлений PC1 и PC2. Первая компонента разделяет людей по полу, а вторая – по месту жительства. Именно эти факторы наиболее сильно влияют на разброс свойств.

[![](https://www.chemometrics.ru/old/Tutorials/pca/fig21.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#'Scores1-2'!D2)

Рис. 21 График счетов (PC1 – PC2) с обозначениями, использованными ранее на [Рис 16](https://www.chemometrics.ru/old/Tutorials/pca.htm#Fig16)

Продолжим изучение, построив график старших счетов PC3– PC4 ([Рис. 22](https://www.chemometrics.ru/old/Tutorials/pca.htm#Fig22) ).&#x20;

[![](https://www.chemometrics.ru/old/Tutorials/pca/fig22.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#'Scores3-4'!I3)

Рис. 22 График счетов (PC3 – PC4) с новыми обозначениями: \
размер и цвет символов отражает доход – чем больше и светлее, тем он больше. Числа представляют возраст

Здесь уже не видно таких отчетливых групп. Тем не менее, внимательно исследовав этот график совместно с таблицей исходных данных, можно, после некоторых усилий, сделать вывод о том, что PC3 отделяет старых/богатых людей от молодых/бедных. Чтобы сделать это более очевидным, мы изменили обозначения. Теперь каждый человек показан кружком, цвет и размер которого меняется в зависимости от дохода – чем больше и светлее, тем больше доход. Рядом показан возраст каждого объекта. Как видно, возраст и доход уменьшается слева направо, т.е. вдоль PC3. А вот смысл PC4 нам по–прежнему не ясен.

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 3.7. Графики нагрузок&#x20;

Чтобы разобраться с этим, построим соответствующие графики нагрузок. Они подскажут нам, какие [переменные](https://www.chemometrics.ru/old/Tutorials/pca.htm#Tab1) и как связаны между собой, что влияет на что.&#x20;

Из графика младших компонент мы сразу видим, что переменные _рост_ (_Height_), _вес_ (_Weight_), _сила_ (_Strength_) и _обувь_ (_Shoes_) образуют компактную группу в правой части графика. Они практически сливаются, что означает их тесную положительную корреляцию. Переменные волосы (_Hair_) и пол (_Sex_) находятся в другой группе, лежащей по диагонали от первой группы. Это свидетельствует о высокой отрицательной корреляции между переменными из этих групп, например, _силой_ (_Strength_) и _полом_ (_Sex_). Наибольшие нагрузки на вторую компоненту имеют переменные _вино_ (_Wine_) и _регион_ (_Region_), также тесно связанные друг с другом. Переменная _доход_ (_Income_) лежит на первом графике напротив переменной _регион_ (_Region_), что отражает дифференциацию состоятельности: Север–Юг. Можно заметить также и антитезу переменных _пиво_ (_Beer_) –_регион_/_вино_(_Region/Wine_).

[![](https://www.chemometrics.ru/old/Tutorials/pca/fig23a.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Loadings!A15)   [![](https://www.chemometrics.ru/old/Tutorials/pca/fig23b.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Loadings!G15)

Рис. 23 Графики нагрузок: PC1 – PC2 и PC3 – PC4&#x20;

Из второго графика мы видим большие нагрузки переменных возраст (_Age_) и доход (_Income_) на ось PC3, что соответствует графику счетов на [Рис. 21](https://www.chemometrics.ru/old/Tutorials/pca.htm#Fig21). Рассмотрим, переменные пиво (_Beer_) и _IQ_. Первая из них имеет большие нагрузки как на PC1, так и на PC2, фактически формируя диагональ взаимоотношений между объектами на графике счетов. Переменная _IQ_ не обнаруживает связи с другими переменным, так как ее значения близки к нулю для нагрузок первых трех PC, и проявляет она себя только в четвертой компоненте. Мы видим, что значения _IQ_ не зависят от места жительства, физиологических характеристик и пристрастий к напиткам.&#x20;

Впервые PCA был применен еще в начале 20–го века в психологических исследованиях, когда верили, что такие показатели, как IQ или криминальное поведение можно объяснить с помощью индивидуальных физиологических и социальных характеристик. Если сравнить результаты PCA с графиками, построенными нами ранее для пар переменных, видно, что PCA сразу дает всеобъемлющее представление о структуре данных, которое можно "охватить одним взглядом" (точнее, с помощью четырех графиков). Поэтому, одна из наиболее сильных сторон PCA в исследовании структур данных – это переход от большого числа не связанных между собой графиков пар переменных к очень небольшому числу графиков счетов и нагрузок.

[Содержание](https://www.chemometrics.ru/old/Tutorials/pca.htm#Contents)

### 3.8. Исследование остатков&#x20;

Сколько главных компонент нужно использовать в этом примере? Для ответа на вопрос нужно исследовать, как изменяется качество описания при увеличении числа PC. Заметим, что в этом примере мы не будем проводить проверку – в этом нет необходимости, т.к. PCA модель нужна только для исследования данных. Она не будет использоваться далее для прогнозирования, классификации, и т.п.

[![](https://www.chemometrics.ru/old/Tutorials/pca/fig24.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Residuals!A50)

Рис. 24 Графики собственных значений

На Рис.24 показано, как, в зависимости от числа PC, меняются собственные значения λ . Видно, что около PC=5 происходит изменение в их поведении. Для расчета показателей TRV и ERV можно получить матрицу остатков **E** для каждого числа главных компонент _A_ и вычислить требуемые показатели. Пример такого расчета для значения _A_=4 приведен на листе [_Residuals_](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Residuals!A1).

[![](https://www.chemometrics.ru/old/Tutorials/pca/fig25.png)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Residuals!A1)

Рис. 25 Анализ остатков

Однако те же характеристики можно получить и проще, если воспользоваться соотношениями

![](https://www.chemometrics.ru/old/Tutorials/pca/image34.gif)

Эти величины представлены на [Рис. 26](https://www.chemometrics.ru/old/Tutorials/pca.htm#Fig26)

[![](https://www.chemometrics.ru/old/Tutorials/pca/fig26.gif)](https://www.chemometrics.ru/old/Tutorials/pca/People.xls#Residuals!J50)

Рис. 26 Графики полной (TRV) и объясненной (ERV) дисперсии остатков

Из этих зависимостей видно, что  для описания данных достаточно четырех PC – они моделируют 94% данных, или, иными словами, шум, оставшийся после проекции на четырехмерное пространство PC1–PC4, оставляет всего 6% от исходных данных.
